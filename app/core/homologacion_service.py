"""
Servicio CRUD para gestionar archivos de homologaci√≥n de m√∫ltiples EPS
Permite agregar, editar, eliminar y consultar c√≥digos de homologaci√≥n
con sistema de cach√© optimizado para mejorar rendimiento
"""
import pandas as pd
import os
from datetime import datetime
import shutil
from typing import Optional, Dict, Any
from functools import lru_cache
import hashlib


class HomologacionService:
    """
    Servicio para gestionar archivos de homologaci√≥n de m√∫ltiples EPS
    con sistema de cach√© optimizado para mejorar rendimiento de b√∫squedas
    """
    
    # Ruta base del directorio de homologaci√≥n en red
    HOMOLOGACION_DIR = r"\\MINERVA\Cartera\GLOSAAP\HOMOLOGADOR"
    
    # Archivos de homologaci√≥n por EPS
    EPS_FILES = {
        "mutualser": "mutualser_homologacion.xlsx",
        "coosalud": "coosalud_homologacion.xlsx"
    }
    
    # Columnas requeridas por EPS (Coosalud solo tiene 2 columnas)
    EPS_COLUMNAS = {
        "mutualser": ['C√≥digo Servicio de la ERP', 'C√≥digo producto en DGH', 'COD_SERV_FACT'],
        "coosalud": ['C√≥digo Servicio de la ERP', 'C√≥digo producto en DGH']
    }
    
    # Columnas por defecto (para compatibilidad)
    COLUMNAS = ['C√≥digo Servicio de la ERP', 'C√≥digo producto en DGH', 'COD_SERV_FACT']
    
    # Cache class-level para compartir entre instancias
    _file_cache: Dict[str, Dict[str, Any]] = {}
    _search_cache: Dict[str, Dict[str, pd.DataFrame]] = {}
    
    def __init__(self, eps: Optional[str] = None):
        """
        Inicializa el servicio de homologaci√≥n con sistema de cach√©
        
        Args:
            eps: Nombre de la EPS (mutualser, coosalud, etc.)
        """
        self.eps = eps
        self.homologacion_path: Optional[str] = None
        self.df: Optional[pd.DataFrame] = None
        self.columnas_actuales: list = self.COLUMNAS  # Columnas seg√∫n EPS
        self._file_hash: Optional[str] = None  # Hash para detectar cambios
        
        if eps:
            self._set_eps(eps)
    
    def _get_file_hash(self, file_path: str) -> str:
        """Calcula hash MD5 de un archivo para detectar cambios"""
        if not os.path.exists(file_path):
            return ""
        
        with open(file_path, 'rb') as f:
            file_hash = hashlib.md5()
            for chunk in iter(lambda: f.read(4096), b""):
                file_hash.update(chunk)
        return file_hash.hexdigest()
    
    def _is_cache_valid(self, cache_key: str) -> bool:
        """Verifica si el cach√© es v√°lido comparando hash del archivo"""
        if cache_key not in self._file_cache:
            return False
            
        cache_entry = self._file_cache[cache_key]
        current_hash = self._get_file_hash(cache_entry.get('file_path', ''))
        
        return current_hash == cache_entry.get('file_hash', '')
    
    def _update_file_cache(self, cache_key: str, df: pd.DataFrame, file_path: str):
        """Actualiza el cach√© de archivo con nuevo DataFrame y hash"""
        file_hash = self._get_file_hash(file_path)
        
        self._file_cache[cache_key] = {
            'df': df.copy(),
            'file_path': file_path,
            'file_hash': file_hash,
            'timestamp': datetime.now()
        }
        
        # Limpiar cach√© de b√∫squeda relacionado
        search_cache_key = f"{cache_key}_search"
        if search_cache_key in self._search_cache:
            del self._search_cache[search_cache_key]
    
    def _clear_search_cache(self, cache_key: str):
        """Limpia el cach√© de b√∫squeda para una EPS espec√≠fica"""
        search_cache_key = f"{cache_key}_search"
        if search_cache_key in self._search_cache:
            del self._search_cache[search_cache_key]
    
    @classmethod
    def clear_all_cache(cls):
        """Limpia todos los cach√©s (√∫til para testing o reinicios)"""
        cls._file_cache.clear()
        cls._search_cache.clear()
        print("üóëÔ∏è Cache de homologaci√≥n limpiado")
    
    @classmethod
    def get_eps_disponibles(cls):
        """
        Obtiene lista de EPS disponibles basado en archivos existentes
        
        Returns:
            Lista de diccionarios con info de cada EPS
        """
        eps_list = []
        try:
            if os.path.exists(cls.HOMOLOGACION_DIR):
                for eps_key, filename in cls.EPS_FILES.items():
                    filepath = os.path.join(cls.HOMOLOGACION_DIR, filename)
                    if os.path.exists(filepath):
                        # Obtener cantidad de registros
                        try:
                            df = pd.read_excel(filepath, nrows=0)
                            df_full = pd.read_excel(filepath)
                            count = len(df_full)
                        except:
                            count = 0
                        
                        eps_list.append({
                            "key": eps_key,
                            "name": eps_key.upper(),
                            "file": filename,
                            "path": filepath,
                            "count": count
                        })
        except Exception as e:
            print(f"Error listando EPS: {e}")
        
        return eps_list
    
    def _set_eps(self, eps: str):
        """Configura la EPS y carga el archivo correspondiente"""
        eps_lower = eps.lower()
        if eps_lower not in self.EPS_FILES:
            raise ValueError(f"EPS '{eps}' no soportada. Opciones: {list(self.EPS_FILES.keys())}")
        
        self.eps = eps_lower
        self.homologacion_path = os.path.join(self.HOMOLOGACION_DIR, self.EPS_FILES[eps_lower])
        # Configurar columnas seg√∫n la EPS
        self.columnas_actuales = self.EPS_COLUMNAS.get(eps_lower, self.COLUMNAS)
        self._cargar()
    
    def cambiar_eps(self, eps: str):
        """
        Cambia a otra EPS
        
        Args:
            eps: Nombre de la EPS
        """
        self._set_eps(eps)
    
    def _cargar(self):
        """Carga el archivo de homologaci√≥n usando cach√© para mejor rendimiento"""
        if not self.homologacion_path:
            self.df = pd.DataFrame(columns=self.columnas_actuales)
            return True
            
        cache_key = f"{self.eps}_homologacion"
        
        try:
            # Verificar si tenemos cach√© v√°lido
            if self._is_cache_valid(cache_key):
                self.df = self._file_cache[cache_key]['df'].copy()
                self._file_hash = self._file_cache[cache_key]['file_hash']
                eps_name = self.eps.upper() if self.eps else "DESCONOCIDA"
                print(f"‚ö° Homologaci√≥n {eps_name} cargada desde cach√©: {len(self.df)} registros") # type: ignore
                return True
            
            # Cargar desde archivo si no hay cach√© v√°lido
            if os.path.exists(self.homologacion_path):
                print(f"üìÅ Cargando homologaci√≥n {self.eps} desde archivo...")
                self.df = pd.read_excel(self.homologacion_path)
                
                # Limpiar columnas
                self.df.columns = self.df.columns.str.strip()
                
                # Mantener solo columnas relevantes para esta EPS
                cols_existentes = [c for c in self.columnas_actuales if c in self.df.columns]
                if cols_existentes:
                    self.df = self.df[cols_existentes].copy()
                
                # Actualizar cach√©
                self._update_file_cache(cache_key, self.df, self.homologacion_path)
                self._file_hash = self._file_cache[cache_key]['file_hash']
                
                eps_name = self.eps.upper() if self.eps else "DESCONOCIDA"
                print(f"‚úÖ Homologaci√≥n {eps_name} cargada: {len(self.df)} registros (guardado en cach√©)")
            else:
                # Crear DataFrame vac√≠o con las columnas de esta EPS
                self.df = pd.DataFrame(columns=self.columnas_actuales)
                print(f"‚ö†Ô∏è Archivo de homologaci√≥n {self.eps or 'desconocida'} no encontrado, creando nuevo")
                
            return True
            
        except Exception as e:
            print(f"‚ùå Error cargando homologaci√≥n: {e}")
            self.df = pd.DataFrame(columns=self.columnas_actuales)
            return False
    
    def _guardar(self):
        """Guarda los cambios en el archivo e invalida cach√©"""
        if not self.homologacion_path:
            print("‚ùå No hay EPS seleccionada")
            return False
            
        try:
            # Crear backup antes de guardar
            if os.path.exists(self.homologacion_path):
                backup_dir = os.path.join(self.HOMOLOGACION_DIR, "backups")
                os.makedirs(backup_dir, exist_ok=True)
                backup_filename = f"{self.eps}_backup_{datetime.now().strftime('%Y%m%d_%H%M%S')}.xlsx"
                backup_path = os.path.join(backup_dir, backup_filename)
                shutil.copy2(self.homologacion_path, backup_path)
                print(f"üìã Backup creado: {backup_filename}")
            
            # Guardar archivo
            if self.df is None:
                print("‚ùå No hay datos para guardar")
                return False
                
            self.df.to_excel(self.homologacion_path, index=False)
            
            # Actualizar cach√© con nueva versi√≥n
            cache_key = f"{self.eps}_homologacion"
            self._update_file_cache(cache_key, self.df, self.homologacion_path)
            self._file_hash = self._file_cache[cache_key]['file_hash']
            
            eps_name = self.eps.upper() if self.eps else "DESCONOCIDA"
            print(f"‚úÖ Archivo {eps_name} guardado (cach√© actualizado)")
            return True
            
        except Exception as e:
            print(f"‚ùå Error guardando: {e}")
            return False
    
    # ==================== CRUD ====================
    
    def listar(self, filtro=None, limite=100):
        """
        Lista c√≥digos de homologaci√≥n
        
        Args:
            filtro: Texto para filtrar (busca en todas las columnas)
            limite: M√°ximo de registros a retornar
            
        Returns:
            DataFrame con los registros
        """
        if self.df is None or self.df.empty:
            return pd.DataFrame(columns=self.columnas_actuales)
        
        df_resultado = self.df.copy()
        
        if filtro:
            filtro = str(filtro).lower()
            mask = df_resultado.apply(
                lambda row: any(filtro in str(v).lower() for v in row), axis=1
            )
            df_resultado = df_resultado[mask]
        
        return df_resultado.head(limite)
    
    def buscar_por_codigo_erp(self, codigo_erp):
        """
        Busca un c√≥digo por el C√≥digo Servicio de la ERP (con cach√© optimizado)
        
        Args:
            codigo_erp: C√≥digo a buscar
            
        Returns:
            Serie con el registro encontrado o None
        """
        if self.df is None or self.df.empty:
            return None
        
        cache_key = f"{self.eps}_search"
        codigo_str = str(codigo_erp).strip()
        
        # Verificar cach√© de b√∫squeda
        if cache_key in self._search_cache:
            search_cache = self._search_cache[cache_key]
            if codigo_str in search_cache:
                cached_result = search_cache[codigo_str]
                if not cached_result.empty:
                    return cached_result.iloc[0]
                return None
        else:
            # Inicializar cach√© de b√∫squeda para esta EPS
            self._search_cache[cache_key] = {}
        
        # B√∫squeda en DataFrame
        mask = self.df['C√≥digo Servicio de la ERP'].astype(str).str.strip() == codigo_str
        resultado = self.df[mask]
        
        # Guardar en cach√© de b√∫squeda
        self._search_cache[cache_key][codigo_str] = resultado.copy()
        
        return resultado.iloc[0] if not resultado.empty else None
    
    def buscar_por_codigo_erp_lote(self, codigos_erp: list) -> Dict[str, Any]:
        """
        Busca m√∫ltiples c√≥digos ERP de forma optimizada usando cach√©
        
        Args:
            codigos_erp: Lista de c√≥digos a buscar
            
        Returns:
            Diccionario con c√≥digos como claves y resultados como valores
        """
        if self.df is None or self.df.empty:
            return {}
        
        cache_key = f"{self.eps}_search"
        resultados = {}
        codigos_a_buscar = []
        
        # Verificar cach√© primero
        if cache_key in self._search_cache:
            search_cache = self._search_cache[cache_key]
            for codigo in codigos_erp:
                codigo_str = str(codigo).strip()
                if codigo_str in search_cache:
                    cached_result = search_cache[codigo_str]
                    resultados[codigo_str] = cached_result.iloc[0] if not cached_result.empty else None
                else:
                    codigos_a_buscar.append(codigo_str)
        else:
            # Inicializar cach√©
            self._search_cache[cache_key] = {}
            codigos_a_buscar = [str(c).strip() for c in codigos_erp]
        
        # Buscar c√≥digos no cacheados
        if codigos_a_buscar:
            df_codigos = self.df['C√≥digo Servicio de la ERP'].astype(str).str.strip()
            for codigo_str in codigos_a_buscar:
                mask = df_codigos == codigo_str
                resultado = self.df[mask]
                
                # Guardar en cach√©
                self._search_cache[cache_key][codigo_str] = resultado.copy()
                resultados[codigo_str] = resultado.iloc[0] if not resultado.empty else None
        
        return resultados
        
        if not resultado.empty:
            return resultado.iloc[0]
        return None
    
    def agregar(self, codigo_erp, codigo_dgh, cod_serv_fact=None):
        """
        Agrega un nuevo c√≥digo de homologaci√≥n
        
        Args:
            codigo_erp: C√≥digo Servicio de la ERP (del archivo de glosa)
            codigo_dgh: C√≥digo producto en DGH (c√≥digo homologado)
            cod_serv_fact: COD_SERV_FACT (opcional, solo para Mutualser)
            
        Returns:
            True si se agreg√≥ correctamente
        """
        try:
            # Validar que no exista
            if self.buscar_por_codigo_erp(codigo_erp) is not None:
                print(f"‚ö†Ô∏è El c√≥digo {codigo_erp} ya existe")
                return False
            
            # Crear registro seg√∫n columnas de la EPS
            nuevo_registro = {
                'C√≥digo Servicio de la ERP': str(codigo_erp).strip(),
                'C√≥digo producto en DGH': str(codigo_dgh).strip()
            }
            
            # Solo agregar COD_SERV_FACT si la EPS lo requiere (Mutualser)
            if 'COD_SERV_FACT' in self.columnas_actuales:
                if cod_serv_fact is None:
                    cod_serv_fact = codigo_dgh
                nuevo_registro['COD_SERV_FACT'] = str(cod_serv_fact).strip()
            
            nuevo = pd.DataFrame([nuevo_registro])
            
            self.df = pd.concat([self.df, nuevo], ignore_index=True)
            
            # Limpiar cach√© de b√∫squeda despu√©s de modificar datos
            self._clear_search_cache(f"{self.eps}_homologacion")
            
            if self._guardar():
                print(f"‚úÖ C√≥digo agregado: {codigo_erp} ‚Üí {codigo_dgh}")
                return True
            return False
            
        except Exception as e:
            print(f"‚ùå Error agregando c√≥digo: {e}")
            return False
    
    def actualizar(self, codigo_erp, codigo_dgh=None, cod_serv_fact=None):
        """
        Actualiza un c√≥digo existente
        
        Args:
            codigo_erp: C√≥digo a actualizar
            codigo_dgh: Nuevo c√≥digo DGH (opcional)
            cod_serv_fact: Nuevo COD_SERV_FACT (opcional, solo para Mutualser)
            
        Returns:
            True si se actualiz√≥ correctamente
        """
        try:
            if self.df is None:
                print("‚ùå No hay datos cargados")
                return False
            
            codigo_str = str(codigo_erp).strip()
            mask = self.df['C√≥digo Servicio de la ERP'].astype(str).str.strip() == codigo_str
            
            if not mask.any():
                print(f"‚ö†Ô∏è C√≥digo {codigo_erp} no encontrado")
                return False
            
            if codigo_dgh:
                self.df.loc[mask, 'C√≥digo producto en DGH'] = str(codigo_dgh).strip()
            # Solo actualizar COD_SERV_FACT si la EPS lo tiene (Mutualser)
            if cod_serv_fact and 'COD_SERV_FACT' in self.columnas_actuales:
                self.df.loc[mask, 'COD_SERV_FACT'] = str(cod_serv_fact).strip()
            
            # Limpiar cach√© de b√∫squeda despu√©s de actualizar
            self._clear_search_cache(f"{self.eps}_homologacion")
            
            if self._guardar():
                print(f"‚úÖ C√≥digo actualizado: {codigo_erp}")
                return True
            return False
            
        except Exception as e:
            print(f"‚ùå Error actualizando c√≥digo: {e}")
            return False
    
    def eliminar(self, codigo_erp):
        """
        Elimina un c√≥digo
        
        Args:
            codigo_erp: C√≥digo a eliminar
            
        Returns:
            True si se elimin√≥ correctamente
        """
        try:
            if self.df is None:
                print("‚ùå No hay datos cargados")
                return False
            
            codigo_str = str(codigo_erp).strip()
            mask = self.df['C√≥digo Servicio de la ERP'].astype(str).str.strip() == codigo_str
            
            if not mask.any():
                print(f"‚ö†Ô∏è C√≥digo {codigo_erp} no encontrado")
                return False
            
            self.df = self.df[~mask].copy()
            
            # Limpiar cach√© de b√∫squeda despu√©s de eliminar
            self._clear_search_cache(f"{self.eps}_homologacion")
            
            if self._guardar():
                print(f"‚úÖ C√≥digo eliminado: {codigo_erp}")
                return True
            return False
            
        except Exception as e:
            print(f"‚ùå Error eliminando c√≥digo: {e}")
            return False
    
    def agregar_multiples(self, codigos):
        """
        Agrega m√∫ltiples c√≥digos de una vez
        
        Args:
            codigos: Lista de tuplas (codigo_erp, codigo_dgh) o (codigo_erp, codigo_dgh, cod_serv_fact)
            
        Returns:
            Cantidad de c√≥digos agregados exitosamente
        """
        agregados = 0
        for codigo in codigos:
            if len(codigo) == 2:
                codigo_erp, codigo_dgh = codigo
                cod_serv_fact = codigo_dgh
            else:
                codigo_erp, codigo_dgh, cod_serv_fact = codigo
            
            # Validar que no exista
            if self.buscar_por_codigo_erp(codigo_erp) is None:
                # Crear registro seg√∫n columnas de la EPS
                nuevo_registro = {
                    'C√≥digo Servicio de la ERP': str(codigo_erp).strip(),
                    'C√≥digo producto en DGH': str(codigo_dgh).strip()
                }
                # Solo agregar COD_SERV_FACT si la EPS lo requiere
                if 'COD_SERV_FACT' in self.columnas_actuales:
                    nuevo_registro['COD_SERV_FACT'] = str(cod_serv_fact).strip()
                
                nuevo = pd.DataFrame([nuevo_registro])
                self.df = pd.concat([self.df, nuevo], ignore_index=True)
                agregados += 1
        
        if agregados > 0 and self._guardar():
            print(f"‚úÖ {agregados} c√≥digos agregados")
        
        return agregados
    
    def obtener_no_homologados(self, codigos_tecnologia):
        """
        Obtiene los c√≥digos que no est√°n en el archivo de homologaci√≥n
        
        Args:
            codigos_tecnologia: Lista de c√≥digos de tecnolog√≠a
            
        Returns:
            Lista de c√≥digos no homologados
        """
        if self.df is None or self.df.empty:
            return codigos_tecnologia
        
        codigos_existentes = set(
            self.df['C√≥digo Servicio de la ERP']
            .dropna().astype(str).str.strip().tolist()
        )
        
        no_homologados = []
        for codigo in codigos_tecnologia:
            codigo_str = str(codigo).strip()
            if codigo_str and codigo_str not in codigos_existentes:
                no_homologados.append(codigo_str)
        
        return list(set(no_homologados))  # √önicos
    
    def get_estadisticas(self):
        """
        Obtiene estad√≠sticas del archivo de homologaci√≥n
        
        Returns:
            Dict con estad√≠sticas
        """
        if self.df is None or self.df.empty:
            return {'total': 0, 'con_dgh': 0, 'con_serv_fact': 0}
        
        stats = {
            'total': len(self.df),
            'con_dgh': self.df['C√≥digo producto en DGH'].notna().sum() if 'C√≥digo producto en DGH' in self.df.columns else 0
        }
        
        # Solo incluir con_serv_fact si la columna existe (Mutualser)
        if 'COD_SERV_FACT' in self.columnas_actuales and 'COD_SERV_FACT' in self.df.columns:
            stats['con_serv_fact'] = self.df['COD_SERV_FACT'].notna().sum()
        else:
            stats['con_serv_fact'] = 0
        
        return stats
    
    def exportar_no_homologados(self, codigos, output_path=None):
        """
        Exporta c√≥digos no homologados a un Excel para revisi√≥n
        
        Args:
            codigos: Lista de c√≥digos no homologados
            output_path: Ruta de salida (opcional)
            
        Returns:
            Ruta del archivo generado
        """
        if not codigos:
            print("No hay c√≥digos para exportar")
            return None
        
        if output_path is None:
            eps_name = self.eps or "general"
            output_path = f"codigos_pendientes_homologar_{eps_name}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.xlsx"
        
        # Crear DataFrame seg√∫n columnas de la EPS
        export_data = {
            'C√≥digo Servicio de la ERP': codigos,
            'C√≥digo producto en DGH': ''
        }
        # Solo agregar COD_SERV_FACT si la EPS lo requiere
        if 'COD_SERV_FACT' in self.columnas_actuales:
            export_data['COD_SERV_FACT'] = ''
        
        df_export = pd.DataFrame(export_data)
        
        df_export.to_excel(output_path, index=False)
        print(f"‚úÖ Exportado: {output_path} ({len(codigos)} c√≥digos pendientes)")
        return output_path

    def verificar_carga_masiva(self, df_carga):
        """
        Verifica los c√≥digos de una carga masiva antes de agregarlos
        
        Args:
            df_carga: DataFrame con columnas 'codigo_eps' y 'codigo_homologo'
            
        Returns:
            Dict con:
                - validos: Lista de tuplas (codigo_eps, codigo_homologo) v√°lidas para agregar
                - duplicados_archivo: Lista de c√≥digos que ya existen en el archivo
                - duplicados_carga: Lista de c√≥digos duplicados dentro del archivo de carga
                - errores: Lista de errores encontrados
        """
        resultado = {
            'validos': [],
            'duplicados_archivo': [],
            'duplicados_carga': [],
            'errores': []
        }
        
        try:
            # Verificar columnas requeridas
            cols_lower = [c.lower().strip() for c in df_carga.columns]
            
            # Buscar columna de c√≥digo EPS
            col_eps = None
            for i, col in enumerate(cols_lower):
                if 'codigo' in col and ('eps' in col or 'erp' in col or 'servicio' in col):
                    col_eps = df_carga.columns[i]
                    break
            if col_eps is None and len(df_carga.columns) >= 1:
                col_eps = df_carga.columns[0]
            
            # Buscar columna de c√≥digo hom√≥logo
            col_homologo = None
            for i, col in enumerate(cols_lower):
                if 'homologo' in col or 'dgh' in col or 'producto' in col:
                    col_homologo = df_carga.columns[i]
                    break
            if col_homologo is None and len(df_carga.columns) >= 2:
                col_homologo = df_carga.columns[1]
            
            if col_eps is None or col_homologo is None:
                resultado['errores'].append("No se encontraron las columnas requeridas (c√≥digo EPS y c√≥digo hom√≥logo)")
                return resultado
            
            # Obtener c√≥digos existentes en el archivo de homologaci√≥n
            codigos_existentes = set()
            if self.df is not None and not self.df.empty:
                codigos_existentes = set(
                    self.df['C√≥digo Servicio de la ERP']
                    .dropna().astype(str).str.strip().tolist()
                )
            
            # Rastrear c√≥digos en la carga para detectar duplicados internos
            codigos_en_carga = {}
            
            for idx, row in df_carga.iterrows():
                codigo_eps = str(row[col_eps]).strip() if pd.notna(row[col_eps]) else ''
                codigo_homologo = str(row[col_homologo]).strip() if pd.notna(row[col_homologo]) else ''
                
                # Validar que no est√©n vac√≠os
                if not codigo_eps or codigo_eps.lower() == 'nan':
                    resultado['errores'].append(f"Fila {idx + 2}: C√≥digo EPS vac√≠o")
                    continue
                if not codigo_homologo or codigo_homologo.lower() == 'nan':
                    resultado['errores'].append(f"Fila {idx + 2}: C√≥digo hom√≥logo vac√≠o para {codigo_eps}")
                    continue
                
                # Verificar si ya existe en el archivo
                if codigo_eps in codigos_existentes:
                    resultado['duplicados_archivo'].append({
                        'codigo': codigo_eps,
                        'homologo_nuevo': codigo_homologo,
                        'fila': idx + 2
                    })
                    continue
                
                # Verificar si est√° duplicado en la misma carga
                if codigo_eps in codigos_en_carga:
                    resultado['duplicados_carga'].append({
                        'codigo': codigo_eps,
                        'homologo': codigo_homologo,
                        'fila_original': codigos_en_carga[codigo_eps]['fila'],
                        'fila_duplicada': idx + 2
                    })
                    continue
                
                # Es v√°lido
                codigos_en_carga[codigo_eps] = {'homologo': codigo_homologo, 'fila': idx + 2}
                resultado['validos'].append((codigo_eps, codigo_homologo))
            
        except Exception as e:
            resultado['errores'].append(f"Error procesando archivo: {str(e)}")
        
        return resultado
    
    def agregar_masivo(self, codigos_validos):
        """
        Agrega m√∫ltiples c√≥digos validados de forma masiva
        
        Args:
            codigos_validos: Lista de tuplas (codigo_eps, codigo_homologo)
            
        Returns:
            Dict con cantidad agregada y errores
        """
        agregados = 0
        errores = []
        
        try:
            nuevos_registros = []
            for codigo_eps, codigo_homologo in codigos_validos:
                # Crear registro seg√∫n columnas de la EPS
                nuevo_registro = {
                    'C√≥digo Servicio de la ERP': str(codigo_eps).strip(),
                    'C√≥digo producto en DGH': str(codigo_homologo).strip()
                }
                # Solo agregar COD_SERV_FACT si la EPS lo requiere (Mutualser)
                if 'COD_SERV_FACT' in self.columnas_actuales:
                    nuevo_registro['COD_SERV_FACT'] = str(codigo_homologo).strip()  # Mismo valor por defecto
                
                nuevos_registros.append(nuevo_registro)
            
            if nuevos_registros:
                df_nuevos = pd.DataFrame(nuevos_registros)
                self.df = pd.concat([self.df, df_nuevos], ignore_index=True)
                
                if self._guardar():
                    agregados = len(nuevos_registros)
                    print(f"‚úÖ {agregados} c√≥digos agregados masivamente")
                else:
                    errores.append("Error al guardar el archivo")
        
        except Exception as e:
            errores.append(f"Error en carga masiva: {str(e)}")
        
        return {'agregados': agregados, 'errores': errores}
